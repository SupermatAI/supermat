{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![supermat](../docs/assets/supermat-logo-black-sub.png)\n",
    "# Supermat Demo\n",
    "\n",
    "## Introduction\n",
    "Supermat focuses on parsing a document while retaining its hierarchical structure unlike most solutions out there.\n",
    "Here is a demonstration to showcase the intermediate representation of supermat's parser framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supermat import FileProcessor, ParsedDocumentType, ParsedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supermat as a Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter path to a sample pdf document here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = Path(\"test_samples/test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handlers\n",
    "You can have multiple handlers for a given file type.\n",
    "\n",
    "You can build your own handler by registering it via `FileProcessor`.\n",
    "\n",
    "In this example we are going to use the PyMuPDF Handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileProcessor.get_handlers(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = FileProcessor.get_handler(\"PyMuPDFParser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_document = handler.parse(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ParsedDocument.dump_json(parsed_document, indent=2).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Technically, we can just run `FileProcessor.parse(pdf_file)` directly instead of fetching a handler.\n",
    "> \n",
    "> This works by fetching the main handler registered in `FileProcessor`.\n",
    "> \n",
    "> For a given file type, you can only have one main handler registered to it.\n",
    "> \n",
    "> Currently, the Adobe is registered as the main handler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supermat as a Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all pdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter dir path of pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files_dir = Path(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = list(pdf_files_dir.glob(\"*.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# This is simply to process all the files in parallel efficiently\n",
    "\n",
    "parsed_files = Parallel(n_jobs=-1, backend=\"threading\")(\n",
    "    delayed(handler.parse_file)(path)\n",
    "    for path in pdf_files\n",
    ")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from supermat.core.models.parsed_document import ParsedDocumentType\n",
    "\n",
    "    parsed_files = cast(list[ParsedDocumentType], parsed_files)\n",
    "\n",
    "documents = list(chain.from_iterable(parsed_docs for parsed_docs in parsed_files))\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from supermat.core.models.parsed_document import ParsedDocumentType\n",
    "\n",
    "    documents = cast(ParsedDocumentType, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup vector db using `SupermatRetriever`\n",
    "\n",
    "> The retriever acts exactly like langchain's retriever module.\n",
    ">\n",
    "> This makes it very easy to make a drop in replacement for existing langchain RAG systems.\n",
    ">\n",
    "> In `vector_store`, you can provide any langchain VectorStore class in it. SupermatRetriver acts as a wrapper around a langchain vector store which makes this very easy to refactor existing RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model=HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supermat.langchain.bindings import SupermatRetriever\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "retriever = SupermatRetriever(\n",
    "    parsed_docs=documents,\n",
    "    vector_store=Chroma(\n",
    "        embedding_function=embedding_model,\n",
    "        collection_name=\"PDFS_SUPERMAT_DEMO\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the retriever chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"bio technology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's compare this with langchain's SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(pdf_files_dir)\n",
    "langchain_documents = loader.load()\n",
    "\n",
    "text_splitter = SemanticChunker(embedding_model, breakpoint_threshold_type=\"percentile\")\n",
    "dataset_chunks = text_splitter.split_documents(langchain_documents)\n",
    "\n",
    "langchain_vector_store = Chroma.from_documents(\n",
    "    documents=dataset_chunks,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"PDFS_LANGCHAIN_DEMO\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_retriever = langchain_vector_store.as_retriever()\n",
    "langchain_retriever.invoke(\"bio technology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup any prefered langchain LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"<ask any question related to the pdf>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from supermat.langchain.bindings import get_default_chain\n",
    "\n",
    "llm_model = OllamaLLM(model=\"deepseek-r1:8b\", temperature=0.0)\n",
    "chain = get_default_chain(retriever, llm_model, substitute_references=False, return_context=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the chain to get answers related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke(ask)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with langchain\n",
    "\n",
    "> _NOTE: This is not the most optimized prompt template_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Use the below information to answer the subsequent question.\n",
    "Please cite the section numbers you take data from.  \n",
    "Provide factual, verifiable information and include references to credible sources where possible. \n",
    "Avoid speculative or unverified content.\n",
    "If the answer cannot be found, write \"I don't know.\"\n",
    "Information:\n",
    "\\\"\\\"\\\"\n",
    "{context}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def format_docs(docs: list[Document]) -> str:\n",
    "    response = [\"{{\" f\"'text':'{doc.page_content}'\" \"}}\" for doc in docs]\n",
    "    return f\"[{','.join(response)}]\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(system_prompt)\n",
    "langchain_chain = (\n",
    "    RunnableParallel({\"context\": retriever|format_docs, \"question\": RunnablePassthrough()}) \n",
    "    | prompt_template \n",
    "    | llm_model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = langchain_chain.invoke(ask)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supermat12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
