{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def override_sys_breakpoint(frame=None):\n",
    "    from IPython.core.debugger import set_trace\n",
    "\n",
    "    set_trace(frame=frame)\n",
    "\n",
    "\n",
    "sys.breakpointhook = override_sys_breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUAD_PATH = Path(\"../data/CUAD_v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "CUAD_QNA_PATH = Path(os.getenv(\"CUAD_QNA_PATH\"))\n",
    "CUAD_QNA_SUBSET_PATH = Path(os.getenv(\"CUAD_QNA_SUBSET_PATH\"))\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files=list(CUAD_QNA_SUBSET_PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supermat.core.parser import FileProcessor\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "documents = list(chain.from_iterable(FileProcessor.parse_file(path) for path in tqdm(pdf_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supermat.langchain.bindings import SupermatRetriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "retriever = SupermatRetriever(\n",
    "    parsed_docs=documents,\n",
    "    vector_store=Chroma(\n",
    "        embedding_function=HuggingFaceEmbeddings(\n",
    "            model_name=\"thenlper/gte-base\",\n",
    "        ),\n",
    "        persist_directory=\"./chromadb\",\n",
    "        collection_name=\"CUAD_TEST\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from langchain.smith.evaluation.runner_utils import TestResult\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.runnables.base import Runnable\n",
    "\n",
    "from supermat.langchain.metrics import (\n",
    "    Accuracy,\n",
    "    CosineSimilarity,\n",
    "    FaithfullnessMetrics,\n",
    "    Rouge1,\n",
    "    Rouge1Precision,\n",
    "    Rouge1Recall,\n",
    "    Rouge2,\n",
    "    Rouge2Precision,\n",
    "    Rouge2Recall,\n",
    "    RougeLsum,\n",
    "    RougeLsumPrecision,\n",
    "    RougeLsumRecall,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Question: {Question}\n",
    "context: {context}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm_model = AzureChatOpenAI(azure_deployment='gpt-35-turbo',api_version=\"2024-05-01-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.cache import BaseCache\n",
    "from langchain_core.callbacks.base import Callbacks\n",
    "\n",
    "RunEvalConfig.LabeledScoreString.model_rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from langchain_benchmarks.extraction.evaluators import get_eval_config\n",
    "\n",
    "rag_evaluation = get_eval_config(llm_model)\n",
    "eval_config = RunEvalConfig.model_validate(\n",
    "    rag_evaluation.model_dump()\n",
    "    | RunEvalConfig(\n",
    "        custom_evaluators=[\n",
    "            FaithfullnessMetrics(llm_model),\n",
    "            Accuracy(llm_model),\n",
    "            CosineSimilarity(),\n",
    "            Rouge1(),\n",
    "            Rouge1Precision(),\n",
    "            Rouge1Recall(),\n",
    "            Rouge2(),\n",
    "            Rouge2Precision(),\n",
    "            Rouge2Recall(),\n",
    "            RougeLsum(),\n",
    "            RougeLsumPrecision(),\n",
    "            RougeLsumRecall(),\n",
    "        ],\n",
    "        input_key=\"Question\",\n",
    "    ).model_dump()\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    RunnableLambda(lambda x: x[\"Question\"])\n",
    "    | RunnableParallel({\"context\": retriever, \"Question\": RunnablePassthrough()})\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"context\": \" \".join(doc.page_content for doc in x[\"context\"]),\n",
    "        \"Question\": x[\"Question\"]\n",
    "    })\n",
    "    | ChatPromptTemplate.from_template(DEFAULT_TEMPLATE)\n",
    "    | llm_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "from langchain_benchmarks.utils import run_without_langsmith\n",
    "\n",
    "from importlib import reload\n",
    "from langchain_benchmarks import utils\n",
    "reload(utils)\n",
    "\n",
    "test_run = utils.run_without_langsmith(\n",
    "    path_or_token_id=CUAD_QNA_PATH.as_posix(),\n",
    "    llm_or_chain_factory=qa_chain,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    concurrency_level=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with pd.ExcelWriter(\"supermat_benchmarks.xlsx\") as writer:\n",
    "    test_run.to_dataframe().to_excel(writer, sheet_name=\"LLM Results\", index=True)\n",
    "    test_run.get_aggregate_feedback().to_excel(writer, sheet_name=\"Agg Results\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supermat12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
